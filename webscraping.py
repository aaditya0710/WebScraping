# -*- coding: utf-8 -*-
"""WebScraping

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PqDD6LjpIJh1xxr5iDcntsfPndDHAHRn
"""

from urllib.request import urlopen
from bs4 import BeautifulSoup

url = "http://www.hubertiming.com/results/2017GPTR10K"
html = urlopen(url)

soup = BeautifulSoup(html,'lxml')
type(soup)

title = soup.title
print(title)

text = soup.get_text()

all_links = soup.find_all('a')
for link in all_links:
  print(link.get("href"))

rows = soup.find_all('tr')
print(rows)

for row in rows:
  row_td = row.find_all('td')
  print(row_td)

str_cells = str(row_td)
clean_text = BeautifulSoup(str_cells,'lxml').get_text()
print(clean_text)

import re

list_rows = []
for row in rows:
  cells = row.find_all('td')
  str_cells = str(cells)
  clean = re.compile('<.*?>')
  clean2 = (re.sub(clean,'',str_cells))
  list_rows.append(clean2)
print(clean2)
type(clean2)

import pandas as pd

df = pd.DataFrame(list_rows)
df.head(10)

df[4:-1]

df1 = df[0].str.split(',',expand=True)
df1.head(10)

df1[0] = df1[0].str.strip('[')
df1.head(10)

col_labels = soup.find_all('th')

col_labels

all_header=[]
col_str = str(col_labels)
clean_text2 = BeautifulSoup(col_str,'lxml').get_text()
all_header.append(clean_text2)
print(all_header)

df2 = pd.DataFrame(all_header)
df2.head()

df3 = df2[0].str.split(',',expand=True)
df3.head()

df4 = pd.concat([df3,df1])
df4.head()

df5 = df4.rename(columns = df4.iloc[0])
df5.head()

